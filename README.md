# ğŸ¥ Medical Image Classification with MobileViT and LoRA

## ğŸ“‹ Overview

This project implements **LoRA fine-tuning** on **MobileViT-Small** for medical image classification across three datasets: Brain Tumor, Chest X-Ray, and Lung Cancer. Compare parameter-efficient fine-tuning vs full fine-tuning approaches.

## ğŸ¤– Pre-trained Models

All models available on ğŸ¤— **Hugging Face Hub**:

- ğŸ§  **Brain Tumor**: [Jesteban247/mobilevit-small-lora-brain-tumor](https://huggingface.co/Jesteban247/mobilevit-small-lora-brain-tumor)
- ğŸ« **Chest X-Ray**: [Jesteban247/mobilevit-small-lora-chest-xray](https://huggingface.co/Jesteban247/mobilevit-small-lora-chest-xray)
- ğŸ§¬ **Lung Cancer**: [Jesteban247/mobilevit-small-lora-lung-cancer](https://huggingface.co/Jesteban247/mobilevit-small-lora-lung-cancer)

## ğŸ“ Project Structure

```
â”œâ”€â”€ ğŸ§  EDA.ipynb              # Dataset download & preprocessing
â”œâ”€â”€ ğŸ‹ï¸ Train.py               # Training script (LoRA + full)
â”œâ”€â”€ ğŸ§ª Experiments.py         # Grid search experiments
â”œâ”€â”€ ğŸ“Š Analysis.ipynb         # Results analysis
â”œâ”€â”€ ğŸ” Prediction.ipynb       # Inference + Grad-CAM
â”œâ”€â”€ ğŸ“¤ Push_to_hub.py         # Hugging Face upload
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Dependencies
```

## ğŸš€ Quick Start

### 1. ğŸ› ï¸ Environment Setup

```bash
# Install Miniconda
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# Initialize Conda
source ~/miniconda3/bin/activate

# Accept Terms of Service
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r

# Create and activate environment
conda create -n medical-vision python=3.12 -y
conda activate medical-vision
pip install -r requirements.txt

# Create Downloads Folder
mkdir -p Downloads
```

### 2. âš¡ Accelerate Configuration (2 GPUs)

This project is intended to run on a single machine with 2 GPUs. Run the interactive Accelerate setup and choose the options below when prompted. You can also create or edit an `accelerate` config file manually.

Interactive (recommended):

```bash
accelerate config
```

When prompted, choose these options (recommended):

- **Compute Environment**: This machine - Running on local hardware
- **Machine Type**: multi-GPU - Multiple GPUs available
- **Number of Machines**: 1 - Single-node setup
- **Check Distributed Operations**: no - Skip error checking for speed (may miss timeouts)
- **Torch Dynamo Optimization**: no - Not using PyTorch's Dynamo compiler
- **DeepSpeed**: no - Not using DeepSpeed for memory optimization
- **FullyShardedDataParallel**: no - Not using FSDP for parameter sharding
- **Megatron-LM**: no - Not using Megatron for large language models
- **GPUs for Training**: n, all - Using all n GPUs
- **NUMA Efficiency**: no - For NVIDIA hardware performance
- **Mixed Precision**: fp16 - 16-bit floating point for faster training

### 3. ğŸ§  Explore EDA.ipynb

**Open and run `EDA.ipynb`** - This notebook:
- Downloads all datasets automatically
- Processes and organizes data (train/val/test splits)
- Creates `Data/` folder with processed datasets
- Generates config files

### 4. ğŸ‹ï¸ Check Train.py

Review the training script that supports both LoRA and full fine-tuning.

### 5. ğŸ§ª Run Experiments

```bash
python Experiments.py
```

This runs grid search comparing LoRA vs full fine-tuning across learning rates.

### 6. ğŸ“Š Jump to Analysis.ipynb

**Open `Analysis.ipynb`** to analyze training results and compare performance.

### 7. ğŸ” Try Prediction.ipynb

**Open `Prediction.ipynb`** for inference with Grad-CAM visualization.

## ğŸ”¬ Key Features

- âš¡ **LoRA Fine-tuning**: ~98% parameter reduction
- ğŸ¥ **Medical Datasets**: Brain tumors, chest X-rays, lung cancer
- ğŸ”¥ **Grad-CAM**: Model explainability visualizations
- ğŸ¤— **Hugging Face**: Pre-trained models ready to use

## âš ï¸ Medical Disclaimer

This project is for research purposes only. Models should not be used for clinical diagnosis without proper validation.